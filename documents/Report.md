
# ğŸ§  Health & Lifestyle â€“ *Reproduzierbarer Bericht*

Dieser Report ist so geschrieben, dass **jede:r im Team** die Aufgabe **selbststÃ¤ndig lÃ¶sen** und **nachvollziehen** kann.

---

## 1) Datensatz & Ziel
- Datei: `health_lifestyle_dataset.csv`  
- Aufgabe: **BinÃ¤re Klassifikation** der Zielvariable `disease_risk` (0 = gesund, 1 = Risiko)  
- Verwendete Features: `bmi`, `daily_steps`, `sleep_hours`, `calories_consumed`, `cholesterol`, `systolic_bp`, `diastolic_bp`, `family_history`

**Dataset Shape:** 100000 Ã— 16  
**Zielverteilung (`disease_risk`)**:  
- 0 (gesund): 75179 (0.7518)  
- 1 (Risiko): 24821 (0.2482)

---

## 2) Vorgehen (Schritt-fÃ¼r-Schritt)

### a) Daten laden & Features definieren (Python-Statements)
```python
import pandas as pd
from sklearn.model_selection import train_test_split

df = pd.read_csv("health_lifestyle_dataset.csv")

X = df[[
    "bmi", "daily_steps", "sleep_hours", "calories_consumed",
    "cholesterol", "systolic_bp", "diastolic_bp", "family_history"
]]
y = df["disease_risk"]
```

Wichtige Schritte und was sie tun:
 

### b) Modelle
Wir vergleichen **6 Modelle**:

### c) Splits & Messung
FÃ¼r jedes Modell messen wir die **Accuracy** bei **Testanteilen 10 %, 30 %, 50 %, 70 %, 90 %**.  
Beim **KNN** wird zusÃ¤tzlich **k âˆˆ {1,3,5,7,9,11,13,15,17,19,21}** ausprobiert und je Split das **beste k** gewÃ¤hlt.

### d) Ergebnisse & Darstellung (Python-Statements)
- train_test_split(X, y, test_size=t, stratify=y, random_state=42): stratifizierter Split fÃ¼r faire Klassenverteilung.
---

## 3) Ergebnisse (exakt aus euren CSVs)

### 3.1 Accuracy je Modell und Testanteil
| Modell | 10 % | 30 % | 50 % | 70 % | 90 % |
| --- | --- | --- | --- | --- | --- |
| Decision Tree | 0.617 | 0.616 | 0.618 | 0.614 | 0.618 |
| KNN (best k=21) | 0.749 | 0.748 | 0.749 | 0.749 | 0.749 |
| Logistic Regression | 0.752 | 0.752 | 0.752 | 0.752 | 0.752 |
| Naive Bayes | 0.752 | 0.752 | 0.752 | 0.752 | 0.752 |
| Random Forest | 0.752 | 0.751 | 0.751 | 0.751 | 0.751 |
| SVM | 0.752 | 0.752 | 0.752 | 0.752 | 0.752 |


ğŸ‘‰ Grundlage: `model_accuracy_over_splits_knn_bestk.csv` (KNN bereits mit *best k* je Split).

### 3.2 Gewinner je Testanteil
- **10 % Test** â†’ **Logistic Regression** mit **0.752**
- **30 % Test** â†’ **Logistic Regression** mit **0.752**
- **50 % Test** â†’ **Logistic Regression** mit **0.752**
- **70 % Test** â†’ **Logistic Regression** mit **0.752**
- **90 % Test** â†’ **Logistic Regression** mit **0.752**

### 3.3 KNN â€“ bestes k je Split
| Testanteil | bestes k | Accuracy |
| --- | --- | --- |
| 10 % | 21 | 0.749 |
| 30 % | 21 | 0.748 |
| 50 % | 21 | 0.749 |
| 70 % | 21 | 0.749 |
| 90 % | 21 | 0.749 |

> ErgÃ¤nzende Detaildateien:  
>
> - `lr_accuracy_by_split.csv` (Logistic Regression â€“ Accuracy je Testanteil)  
> - `knn_accuracy_grid_over_k_and_splits.csv` (komplette kÃ—Split-Matrix)  
> - `knn_bestk_per_split.csv` (bestes k je Testanteil)
>

---

## 4) Visualisierung


### 4.1 Warum gibt es zwei sehr Ã¤hnliche Diagramme je Modell?

In den Notebooks gibt es pro Modell bewusst zwei Plotâ€‘Varianten:

- 10/30/50/70/90 % â€“ Tabelle + Plot: schnelle Liveâ€‘Ausgabe direkt nach der Messung, inkl. print()/display der Rohâ€‘Tabelle. Praktisch fÃ¼r Exploration und unmittelbares Feedback.
- Ãœbersichtstabelle & Plot (Accuracy je Testanteil): standardisierte Darstellung mit konsistenten Achsen/Labels/xticks und oft zusÃ¤tzlichem CSVâ€‘Export. Dient der Vergleichbarkeit Ã¼ber alle Modelle und der Abgabe.

Kurz: Der erste Plot ist der schnelle Check, der zweite ist die â€saubereâ€œ Version fÃ¼r Bericht/Export. Inhalte sind Ã¤hnlich, aber die Formatierung ist vereinheitlicht und die Daten werden zusÃ¤tzlich gespeichert.

---

## 5) Interpretation

- Spitze: In unseren Ergebnissen liegen Logistische Regression, SVM und Naive Bayes praktisch gleichauf und bilden die besten Accuracies Ã¼ber die Splits.
- Random Forest liegt knapp dahinter, bleibt aber robust Ã¼ber unterschiedliche Testanteile.
- Decision Tree fÃ¤llt deutlich ab und ist variabler (hÃ¶here Varianz/Overfittingâ€‘Tendenz bei weniger Trainingsdaten).
- KNN liegt unterhalb der Topâ€‘Modelle; die Performance hÃ¤ngt spÃ¼rbar von k ab. Mittlere k liefern meist den besten Kompromiss; sehr kleine k neigen zu hoher Varianz.

---

## 6) Reproduzierbarer Beispielcode (Template)

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv("health_lifestyle_dataset.csv")
X = df[[
    "bmi","daily_steps","sleep_hours","calories_consumed",
    "cholesterol","systolic_bp","diastolic_bp","family_history"
]]
y = df["disease_risk"]

test_sizes = [0.1, 0.3, 0.5, 0.7, 0.9]

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "Naive Bayes": GaussianNB(),
    "SVM": SVC(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
}

rows = []
k_list = [1,3,5,7,9,11,13,15,17,19,21]
for t in test_sizes:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t, random_state=42, stratify=y)
    # Basismodelle
    for name, mdl in models.items():
        mdl.fit(X_train, y_train)
        acc = mdl.score(X_test, y_test)
        rows.append({"Model": name, "Testanteil": t, "Accuracy": acc})
    # KNN best-k
    best_k, best_acc = None, -1
    for k in k_list:
        knn = KNeighborsClassifier(n_neighbors=k).fit(X_train, y_train)
        acc = knn.score(X_test, y_test)
        if acc > best_acc:
            best_k, best_acc = k, acc
    rows.append({"Model": f"KNN (best k={best_k})", "Testanteil": t, "Accuracy": best_acc})

pd.DataFrame(rows).to_csv("model_accuracy_over_splits_knn_bestk.csv", index=False)
```


## 6.1) CSVâ€‘Exporte â€“ Inhalt und Zweck

Nur die Dateien, die direkt im Ordner `OutputCSV` liegen (ohne Archiv):

- model_accuracy_over_splits_knn_bestk.csv
    - Zweck: Gesamter Vergleich aller Modelle Ã¼ber die fÃ¼nf Testanteile; KNN ist pro Split bereits mit dem jeweils besten k enthalten.
    - Spalten (Header): Modell, Testanteil, Trainanteil, Accuracy

- knn_accuracy_grid_over_k_and_splits.csv
    - Zweck: Langformatâ€‘Matrix Ã¼ber alle Kombinationen (Testanteil Ã— k) fÃ¼r KNN; Basis fÃ¼r Pivot/Heatmap und Linienplot Accuracy vs. k.
    - Spalten (Header): Testanteil, k, Accuracy

- knn_bestk_per_split.csv
    - Zweck: KurzÃ¼berblick Ã¼ber das beste k je Testanteil inklusive zugehÃ¶riger Accuracy.
    - Spalten (Header): Testanteil, Bestes k, Accuracy

- lr_accuracy_by_split.csv
    - Zweck: Logisticâ€‘Regression â€“ Accuracy Ã¼ber die fÃ¼nf Testanteile (einzelnes Modell).
    - Spalten (Header): Testanteil, Trainanteil, Accuracy

Hinweis: Weitere, gleichartige Dateien pro Modell (z. B. fÃ¼r NB/SVM/DT/RF) wurden in den Archivâ€‘Unterordner verschoben, um die Abgabe Ã¼bersichtlich zu halten. Bei Bedarf kÃ¶nnen sie jederzeit wiederhergestellt werden.

---





